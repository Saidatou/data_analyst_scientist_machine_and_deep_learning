{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f416d5",
   "metadata": {},
   "source": [
    "# Importation des packages et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebf743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, \n",
    "                                     LeaveOneOut, LeavePOut,\n",
    "                                     cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3df0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaf4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553ed05",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ce528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Création du modèle\n",
    "model = LogisticRegression(solver='liblinear', multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361544a",
   "metadata": {},
   "source": [
    "# Technique Validation Hold Out/ Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8f1a9",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation hold-out\n",
    "\n",
    "La validation hold-out est une méthode simple et courante pour évaluer les performances d'un modèle d'apprentissage automatique. Elle consiste à diviser le jeu de données en un ensemble d'entraînement et un ensemble de test. L'ensemble d'entraînement est utilisé pour entraîner le modèle, tandis que l'ensemble de test est utilisé pour évaluer les performances du modèle.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation hold-out est simple et rapide à mettre en œuvre.\n",
    "- Elle permet d'évaluer les performances du modèle sur des données qui n'ont pas été utilisées pour l'entraînement.\n",
    "- Elle est utile lorsque le jeu de données est suffisamment grand pour être divisé en un ensemble d'entraînement et un ensemble de test représentatifs.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La division du jeu de données en deux ensembles peut entraîner une perte de précision et de généralité dans les performances du modèle.\n",
    "- Si l'ensemble de test est trop petit, les performances du modèle peuvent être surévaluées ou sous-estimées.\n",
    "- Si la division est mal effectuée, elle peut conduire à des biais de sélection et affecter les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8428902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec Train/Test Split: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Technique 1 : Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "score_split = model.score(X_test, y_test)\n",
    "print(f\"Score avec Train/Test Split: {score_split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c1228",
   "metadata": {},
   "source": [
    "# Validation KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5198f",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation croisée K-fold\n",
    "\n",
    "La validation croisée K-fold est une méthode d'évaluation de modèle plus avancée que la validation hold-out. Elle consiste à diviser le jeu de données en K sous-ensembles (ou \"folds\") de taille égale (ou presque), puis à entraîner et évaluer le modèle K fois. À chaque fois, un sous-ensemble différent est utilisé pour l'évaluation, tandis que les K-1 autres sont utilisés pour l'entraînement.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation croisée K-fold est plus robuste et plus précise que la validation hold-out, car elle utilise l'ensemble de données dans son intégralité pour l'entraînement et l'évaluation du modèle.\n",
    "- Elle permet d'obtenir une estimation plus fiable de la performance du modèle en moyenne, ainsi que de la variance de cette performance.\n",
    "- Elle est utile lorsque le jeu de données est petit ou lorsque l'on souhaite maximiser l'utilisation de toutes les données disponibles pour l'entraînement et l'évaluation.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La validation croisée K-fold est plus complexe et plus coûteuse en temps de calcul que la validation hold-out, car elle nécessite K entraînements et évaluations du modèle.\n",
    "- Elle peut être moins efficace lorsque le jeu de données est très grand, car les temps de calcul peuvent devenir prohibitifs.\n",
    "- Si les folds ne sont pas choisis de manière représentative ou s'ils sont trop petits, cela peut affecter les performances du modèle et introduire des biais de sélection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebd0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores avec K-Fold Cross Validation: [1.         0.93333333 0.93333333 0.96666667 0.96666667]\n",
      "Moyenne des scores K-Fold: 0.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Technique 2 : K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_kfold = cross_val_score(model, X, y, cv=kfold)\n",
    "print(f\"Scores avec K-Fold Cross Validation: {scores_kfold}\")\n",
    "print(f\"Moyenne des scores K-Fold: {np.mean(scores_kfold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c40667",
   "metadata": {},
   "source": [
    "# Stratified KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa5837",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation croisée stratifiée K-fold\n",
    "\n",
    "La validation croisée stratifiée K-fold est une variante de la validation croisée K-fold qui vise à préserver la répartition des classes dans les différents folds. Elle est particulièrement utile lorsque l'on travaille avec des données déséquilibrées, c'est-à-dire lorsque certaines classes sont sous-représentées.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation croisée stratifiée K-fold est plus robuste que la validation croisée K-fold pour les jeux de données déséquilibrés, car elle préserve la répartition des classes dans les différents folds.\n",
    "- Elle permet d'obtenir une estimation plus fiable de la performance du modèle pour chaque classe individuellement, ainsi que pour l'ensemble du jeu de données.\n",
    "- Elle est utile lorsque l'on travaille avec des données déséquilibrées ou lorsque l'on souhaite maximiser l'utilisation de toutes les données disponibles pour l'entraînement et l'évaluation.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La validation croisée stratifiée K-fold est plus complexe et plus coûteuse en temps de calcul que la validation croisée K-fold, car elle nécessite de préserver la répartition des classes dans les différents folds.\n",
    "- Elle peut être moins efficace lorsque les données sont très déséquilibrées, car cela peut conduire à des folds de taille trop petite pour certaines classes, ce qui peut affecter les performances du modèle.\n",
    "- Si la stratification n'est pas effectuée correctement, cela peut conduire à des biais de sélection et affecter les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f133e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores avec Stratified K-Fold Cross Validation: [0.96666667 1.         0.9        0.93333333 1.        ]\n",
      "Moyenne des scores Stratified K-Fold: 0.96\n"
     ]
    }
   ],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_stratified_kfold = cross_val_score(model, X, y, cv=stratified_kfold)\n",
    "print(f\"Scores avec Stratified K-Fold Cross Validation: {scores_stratified_kfold}\")\n",
    "print(f\"Moyenne des scores Stratified K-Fold: {np.mean(scores_stratified_kfold)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ed90d",
   "metadata": {},
   "source": [
    "# Stratified Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda0e60",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation croisée stratifiée train-test split\n",
    "\n",
    "La validation croisée stratifiée train-test split est une méthode d'évaluation de modèle qui consiste à diviser le jeu de données en un ensemble d'entraînement et un ensemble de test, tout en préservant la répartition des classes dans les deux ensembles. Elle est similaire à la validation hold-out, mais elle vise à éviter les biais de sélection liés à la répartition des classes.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation croisée stratifiée train-test split est simple et rapide à mettre en œuvre, comme la validation hold-out.\n",
    "- Elle permet d'évaluer les performances du modèle sur des données qui n'ont pas été utilisées pour l'entraînement, tout en préservant la répartition des classes.\n",
    "- Elle est utile lorsque le jeu de données est suffisamment grand pour être divisé en un ensemble d'entraînement et un ensemble de test représentatifs.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La validation croisée stratifiée train-test split peut être moins robuste que la validation croisée K-fold ou la validation leave-one-out pour les jeux de données très petits ou très déséquilibrés.\n",
    "- Si l'ensemble de test est trop petit, les performances du modèle peuvent être surévaluées ou sous-estimées.\n",
    "- Si la stratification n'est pas effectuée correctement, cela peut conduire à des biais de sélection et affecter les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef28da",
   "metadata": {},
   "source": [
    "# Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1ebce",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation leave-one-out\n",
    "\n",
    "La validation leave-one-out est une méthode d'évaluation de modèle qui consiste à diviser le jeu de données en K sous-ensembles, chacun étant constitué d'un seul exemple (ou \"leave-one-out\"), puis à entraîner et évaluer le modèle K fois. À chaque fois, un seul exemple est utilisé pour l'évaluation, tandis que les K-1 autres sont utilisés pour l'entraînement.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation leave-one-out est la méthode d'évaluation la plus précise que l'on puisse utiliser, car elle utilise toutes les données disponibles pour l'entraînement et l'évaluation.\n",
    "- Elle permet d'obtenir une estimation très fiable de la performance du modèle, car elle ne sous-évalue jamais cette performance.\n",
    "- Elle est particulièrement utile lorsque l'on travaille avec des jeux de données très petits.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La validation leave-one-out est très coûteuse en temps de calcul, car elle nécessite K entraînements et évaluations du modèle.\n",
    "- Elle peut être moins efficace lorsque le jeu de données est très grand, car les temps de calcul peuvent devenir prohibitifs.\n",
    "- Elle peut être sensible aux données aberrantes (outliers), car elle entraîne et évalue le modèle pour chaque exemple individuellement, ce qui peut conduire à des résultats instables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ed5c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores avec Leave-One-Out Cross Validation: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Moyenne des scores Leave-One-Out: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "scores_loo = cross_val_score(model, X, y, cv=loo)\n",
    "print(f\"Scores avec Leave-One-Out Cross Validation: {scores_loo}\")\n",
    "print(f\"Moyenne des scores Leave-One-Out: {np.mean(scores_loo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97625fd",
   "metadata": {},
   "source": [
    "# Leave P Out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832abeb",
   "metadata": {},
   "source": [
    "## Avantages et inconvénients de la validation leave-p-out\n",
    "\n",
    "La validation leave-p-out est une méthode d'évaluation de modèle qui consiste à diviser le jeu de données en K sous-ensembles, chacun étant constitué de p exemples, puis à entraîner et évaluer le modèle K fois. À chaque fois, p exemples sont utilisés pour l'évaluation, tandis que les K-p autres sont utilisés pour l'entraînement.\n",
    "\n",
    "Voici les avantages et les inconvénients de cette méthode :\n",
    "\n",
    "### Avantages :\n",
    "\n",
    "- La validation leave-p-out est plus précise que la validation croisée K-fold pour les jeux de données de petite ou moyenne taille, car elle utilise plus d'exemples pour l'entraînement et l'évaluation.\n",
    "- Elle permet d'obtenir une estimation plus fiable de la performance du modèle que la validation hold-out, car elle utilise plus d'exemples pour l'évaluation.\n",
    "- Elle est particulièrement utile lorsque l'on travaille avec des jeux de données de petite ou moyenne taille.\n",
    "\n",
    "### Inconvénients :\n",
    "\n",
    "- La validation leave-p-out est coûteuse en temps de calcul, car elle nécessite K entraînements et évaluations du modèle.\n",
    "- Elle peut être moins efficace que la validation croisée K-fold pour les jeux de données très grands, car les temps de calcul peuvent devenir prohibitifs.\n",
    "- Elle peut être sensible aux données aberrantes (outliers), car elle entraîne et évalue le modèle pour chaque sous-ensemble individuellement, ce qui peut conduire à des résultats instables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666422e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores avec Leave-P-Out Cross Validation: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]\n",
      "Moyenne des scores Leave-P-Out: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natachanjongwayepnga/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "435 fits failed out of a total of 435.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "435 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/natachanjongwayepnga/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/natachanjongwayepnga/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/natachanjongwayepnga/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 1143, in _fit_liblinear\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Technique 5 : Leave-P-Out Cross Validation (avec P=2)\n",
    "lpo = LeavePOut(p=2)\n",
    "scores_lpo = cross_val_score(model, X[:30], y[:30], cv=lpo)  # Limitez à 30 échantillons pour réduire le temps de calcul\n",
    "print(f\"Scores avec Leave-P-Out Cross Validation: {scores_lpo}\")\n",
    "print(f\"Moyenne des scores Leave-P-Out: {np.mean(scores_lpo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee8cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
